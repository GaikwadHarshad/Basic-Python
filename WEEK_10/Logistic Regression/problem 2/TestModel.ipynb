{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    " # import libraries\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "import  array\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib.util\n",
    "from matplotlib.colors import ListedColormap\n",
    "import array\n",
    "from  sklearn.preprocessing import LabelEncoder\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "import csv\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing template file \n",
    "spec = importlib.util.spec_from_file_location(\"Template\", \"/home/admin1/PycharmProjects/Basic Python/myprograms/WEEK_10/UtilityTemplate/UtilTemplate.py\")\n",
    "foo = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(foo)\n",
    "# creating object of Template class\n",
    "log_template = foo.Template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 537 rows and 9 Columns\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "test_dataset = log_template.read_csv('CSV_Files/test.csv')\n",
    "print(\"Dataset has {} rows and {} Columns\".format(test_dataset.shape[0],test_dataset.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model training\n",
    "file = open('Pickle File/TrainPickle.pkl', 'rb')\n",
    "classifier = pickle.load(file)\n",
    "scaling =  pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate label and features\n",
    "x_test =  test_dataset.iloc[:,:-1].values\n",
    "y_test = test_dataset.iloc[:,8].values\n",
    "# x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = pd.DataFrame(x_test)\n",
    "type(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding on x data\n",
    "x_test = log_template.one_hot_encode(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode dependent variable      \n",
    "label_encoder_y = LabelEncoder()\n",
    "y_test = label_encoder_y.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 160)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform transform on test data\n",
    "x_test = scaling.transform(x_test)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on model by test data\n",
    "prediction =  log_template.prediction(x_test, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for describe performance of classification model\n",
    "cfm_test = sklearn.metrics.confusion_matrix(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 91.3558671019781\n"
     ]
    }
   ],
   "source": [
    "# get accuracy\n",
    "accuracy =  sklearn.metrics.balanced_accuracy_score(y_test,prediction)*100\n",
    "print(\"Test Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
